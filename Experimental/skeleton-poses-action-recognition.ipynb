{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"All necessary libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "WINDOW_SIZE_FRAMES = 150\n",
    "STEP_SIZE_FRAMES = 30\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "INPUT_FEATURES = 90 # 36 (normalized poses) + 36 (velocities) + 18 (orientation angles)\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Global seed set to {seed_value}\")\n",
    "\n",
    "def load_and_label_files(data_root: str) -> pd.DataFrame:\n",
    "\n",
    "    all_csv_files = glob(os.path.join(data_root, '**', '*.csv'), recursive=True)\n",
    "    labeled_data = [{'path': file_path, 'label': 1 if 'Potential_shoplifter' in file_path else 0} for file_path in all_csv_files]\n",
    "    df_files = pd.DataFrame(labeled_data)\n",
    "    print(f\"Found {len(df_files)} total CSV files.\")\n",
    "    if not df_files.empty:\n",
    "        print(\"\\nValue counts for labels:\")\n",
    "        print(df_files['label'].value_counts())\n",
    "    return df_files\n",
    "\n",
    "def parse_poses_from_string(poses_str: str) -> np.ndarray:\n",
    "    \n",
    "    try:\n",
    "        return np.array(json.loads(poses_str)).reshape(18, 2)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return np.zeros((18, 2))\n",
    "\n",
    "# def extract_features(csv_path: str) -> np.ndarray | None:\n",
    "  \n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     if df.empty or 'POSES' not in df.columns:\n",
    "#         return None\n",
    "\n",
    "#     raw_poses = np.array(df['POSES'].apply(parse_poses_from_string).tolist()) \n",
    "   \n",
    "#     #raw_poses shape: (T, 18, 2) => (frames, keypoints, (x,y))\n",
    "#     neck_positions = raw_poses[:, 1:2, :] \n",
    "\n",
    "#     normalized_poses = raw_poses - neck_positions # We normalize the poses with respect to the neck position\n",
    "\n",
    "#     velocities = np.diff(raw_poses, axis=0, prepend=raw_poses[0:1]) # Compute velocities\n",
    "\n",
    "#     neck_trajectory = raw_poses[:, 1, :] # Extract neck trajectory why? Because the neck is a key point for understanding the body's movement.\n",
    "\n",
    "#     deltas = np.diff(neck_trajectory, axis=0, prepend=[neck_trajectory[0]])  # Compute deltas why? Because the deltas represent the change in position of the neck over time.\n",
    "\n",
    "#     orientation_angles_deg = np.degrees(np.arctan2(deltas[:, 1], deltas[:, 0])) # Compute orientation angles why? Because the orientation angles help in understanding the direction of movement.\n",
    "    \n",
    "#     # we only use neck orientation as the key point for understanding the body's movement why? Because the neck is a key point for understanding the body's movement\n",
    "#     # but it shows limitation so maybe adding other keypoints like shoulders or hips could provide more context.\n",
    "\n",
    "#     return np.concatenate([\n",
    "#         normalized_poses.reshape(raw_poses.shape[0], -1),\n",
    "#         velocities.reshape(raw_poses.shape[0], -1),\n",
    "#         orientation_angles_deg.reshape(-1, 1)\n",
    "#     ], axis=1)\n",
    "\n",
    "def extract_features(csv_path: str) -> np.ndarray | None:\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    raw_poses = np.array(df['POSES'].apply(parse_poses_from_string).tolist())\n",
    "    \n",
    "    neck_positions = raw_poses[:, 1:2, :]  \n",
    "    normalized_poses = raw_poses - neck_positions\n",
    "    velocities = np.diff(raw_poses, axis=0, prepend=raw_poses[0:1])\n",
    "\n",
    "    all_orientation_angles = []\n",
    "    for i in range(raw_poses.shape[1]):\n",
    "        joint_trajectory = raw_poses[:, i, :]\n",
    "        \n",
    "        deltas = np.diff(joint_trajectory, axis=0, prepend=[joint_trajectory[0]])\n",
    "        \n",
    "        orientation_deg = np.degrees(np.arctan2(deltas[:, 1], deltas[:, 0]))\n",
    "        all_orientation_angles.append(orientation_deg)\n",
    "        \n",
    "    all_orientations_feature = np.stack(all_orientation_angles, axis=1)\n",
    "\n",
    "    return np.concatenate([\n",
    "        normalized_poses.reshape(raw_poses.shape[0], -1),  # Shape: (T, 36)\n",
    "        velocities.reshape(raw_poses.shape[0], -1),      # Shape: (T, 36)\n",
    "        all_orientations_feature                           # Shape: (T, 18)\n",
    "    ], axis=1)\n",
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "print(f\"Using device: {device}\")\n",
    "data_root = r'C:\\Users\\asus\\Desktop\\Ain-Guard Assesment\\csvs_Skeleton_poses_normal_potential_shoplifter'\n",
    "#data_root=r'/kaggle/input/skeleton-poses-normalvsshoplifter'\n",
    "df_files = load_and_label_files(data_root)\n",
    "\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_group_id(file_path: str) -> str:\n",
    "\n",
    "    return os.path.basename(file_path).replace('.csv', '')[-23:]\n",
    "\n",
    "def create_sliding_windows(sequences: list, labels: list, window_size: int, step_size: int):\n",
    "\n",
    "    windowed_sequences, windowed_labels = [], []\n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        # Sequences shorter than window_size are dropped (no padding)\n",
    "        # Overlap amount = window_size - step_size (here 150 - 30 = 120 frames overlap â†’ heavy redundancy).\n",
    "\n",
    "        if seq.shape[0] >= window_size:\n",
    "            for start in range(0, seq.shape[0] - window_size + 1, step_size):\n",
    "\n",
    "                windowed_sequences.append(seq[start:start + window_size])\n",
    "\n",
    "                windowed_labels.append(labels[i])\n",
    "\n",
    "    return np.array(windowed_sequences), np.array(windowed_labels)\n",
    "\n",
    "print(\" Processing all CSV files into feature sequences \")\n",
    "\n",
    "all_sequences, all_labels, all_groups, all_paths = [], [], [], []\n",
    "\n",
    "for _, row in tqdm(df_files.iterrows(), total=len(df_files), desc=\"Extracting Features\"):\n",
    "\n",
    "    features = extract_features(row['path'])\n",
    "\n",
    "    if features is not None and len(features) > 0:\n",
    "        \n",
    "        all_sequences.append(features)\n",
    "        all_labels.append(row['label'])\n",
    "        all_groups.append(get_group_id(row['path']))\n",
    "        all_paths.append(row['path'])\n",
    "\n",
    "print(\"\\n Splitting data by group to prevent leakage \")\n",
    "\n",
    "gss_train_temp = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_group_indices, temp_group_indices = next(gss_train_temp.split(all_sequences, all_labels, all_groups))\n",
    "\n",
    "train_sequences = [all_sequences[i] for i in train_group_indices]\n",
    "train_labels = [all_labels[i] for i in train_group_indices]\n",
    "\n",
    "temp_sequences = [all_sequences[i] for i in temp_group_indices]\n",
    "temp_labels = [all_labels[i] for i in temp_group_indices]\n",
    "temp_groups = np.array(all_groups)[temp_group_indices]\n",
    "temp_paths = [all_paths[i] for i in temp_group_indices]\n",
    "\n",
    "print(\"\\n Creating datasets: augmented for training, and both windowed & full-length for val/test \")\n",
    "\n",
    "X_train_windowed, y_train_windowed = create_sliding_windows(\n",
    "    train_sequences, train_labels, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES\n",
    ")\n",
    "\n",
    "gss_val_test = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "val_indices, test_indices = next(gss_val_test.split(temp_sequences, temp_labels, temp_groups))\n",
    "\n",
    "X_val_long = [temp_sequences[i] for i in val_indices]\n",
    "y_val_long = [temp_labels[i] for i in val_indices]\n",
    "X_test_long = [temp_sequences[i] for i in test_indices]\n",
    "y_test_long = [temp_labels[i] for i in test_indices]\n",
    "test_paths_long = [temp_paths[i] for i in test_indices]\n",
    "\n",
    "X_val_windowed, y_val_windowed = create_sliding_windows(X_val_long, y_val_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "X_test_windowed, y_test_windowed = create_sliding_windows(X_test_long, y_test_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train_windowed).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_windowed).long()\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=g)\n",
    "\n",
    "print(\"\\n Data Preparation Complete \")\n",
    "print(f\"Total original videos processed: {len(all_sequences)}\")\n",
    "print(f\"Training on {len(X_train_tensor)} augmented windows (from {len(train_sequences)} videos).\")\n",
    "print(f\"Validating on {len(X_val_long)} full-length videos.\")\n",
    "print(f\"Testing on {len(X_test_long)} full-length videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RealTimeClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.5):\n",
    "        super(RealTimeClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out, _ = self.lstm(x)\n",
    "        attention_scores = self.attention(out)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        context_vector = torch.sum(attention_weights * out, dim=1)\n",
    "        context_vector_dropped = self.dropout(context_vector)\n",
    "        return self.fc(context_vector_dropped)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 2.0, reduction: str = 'mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.alpha[targets] * (1 - pt)**self.gamma * ce_loss)\n",
    "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()\n",
    "\n",
    "def evaluate_and_report_on_test_set(\n",
    "    model: nn.Module,\n",
    "    test_sequences: list[np.ndarray],\n",
    "    test_labels: list[int],\n",
    "    device: torch.device\n",
    "):\n",
    "    model.eval()\n",
    "    all_window_preds, all_window_labels = [], []\n",
    "    video_suspicion_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, long_seq_np in enumerate(tqdm(test_sequences, desc=\"Evaluating Test Set\")):\n",
    "            y_true_video = test_labels[i]\n",
    "            seq_windows_tensors = []\n",
    "            if long_seq_np.shape[0] >= WINDOW_SIZE_FRAMES:\n",
    "                for start in range(0, long_seq_np.shape[0] - WINDOW_SIZE_FRAMES + 1, STEP_SIZE_FRAMES):\n",
    "                    window = long_seq_np[start:start + WINDOW_SIZE_FRAMES]\n",
    "                    seq_windows_tensors.append(torch.from_numpy(window))\n",
    "            if not seq_windows_tensors:\n",
    "                video_suspicion_scores.append(0.0)\n",
    "                continue\n",
    "            windows_batch = torch.stack(seq_windows_tensors).float().to(device)\n",
    "            outputs = model(windows_batch)\n",
    "            _, predicted_windows = torch.max(outputs, 1)\n",
    "            all_window_preds.extend(predicted_windows.cpu().numpy())\n",
    "            all_window_labels.extend([y_true_video] * len(predicted_windows))\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            def aggregate_window_probs(probabilities, mode=\"mean\", k=3, p0=0.6):\n",
    "                probs = probabilities.cpu().numpy()\n",
    "                if mode == \"mean\":\n",
    "                    return probs.mean()\n",
    "                if mode == \"max\":\n",
    "                    return probs.max()\n",
    "                if mode == \"median\":\n",
    "                    return np.median(probs)\n",
    "                if mode == \"topk_mean\":\n",
    "                    k = min(k, len(probs))\n",
    "                    return np.sort(probs)[-k:].mean()\n",
    "                if mode == \"prop_above\":\n",
    "                    return (probs >= p0).mean()\n",
    "                raise ValueError(f\"Unknown mode {mode}\")\n",
    "            avg_suspicion_score = aggregate_window_probs(probabilities, mode=\"mean\")\n",
    "            video_suspicion_scores.append(avg_suspicion_score)\n",
    "\n",
    "    plot_report_and_matrix(all_window_labels, all_window_preds, \"Test Set Evaluation (Per-Window)\")\n",
    "\n",
    "    simple_accuracy = evaluate_realistically(model, test_sequences, test_labels, device, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "    print(f\"\\n Test Set Evaluation (Simple Per-Video) \")\n",
    "    print(f\"Accuracy (if any window is 1, predict 1): {simple_accuracy:.2f}%\")\n",
    "\n",
    "    y_true_video_labels = test_labels\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_video_labels, video_suspicion_scores)\n",
    "    f1_scores = np.nan_to_num(2 * (precisions * recalls) / (precisions + recalls))\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    y_pred_thresholded = [1 if score >= best_threshold else 0 for score in video_suspicion_scores]\n",
    "    plot_report_and_matrix(y_true_video_labels, y_pred_thresholded, f\"Test Set Evaluation (Optimal Threshold: {best_threshold:.2f})\")\n",
    "\n",
    "def plot_report_and_matrix(y_true, y_pred, title):\n",
    "    print(f\"\\n {title} \")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Normal', 'Potential Shoplifter'], zero_division=0))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Normal', 'Potential Shoplifter'], yticklabels=['Normal', 'Potential Shoplifter'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_realistically(model, long_sequences, long_labels, device, window_size, step_size):\n",
    "    model.eval()\n",
    "    y_pred_final = []\n",
    "    with torch.no_grad():\n",
    "        for long_seq_np in long_sequences:\n",
    "            seq_windows_tensors = []\n",
    "            if long_seq_np.shape[0] >= window_size:\n",
    "                for start in range(0, long_seq_np.shape[0] - window_size + 1, step_size):\n",
    "                    seq_windows_tensors.append(torch.from_numpy(long_seq_np[start:start + window_size]))\n",
    "            if not seq_windows_tensors:\n",
    "                final_video_prediction = 0\n",
    "            else:\n",
    "                outputs = model(torch.stack(seq_windows_tensors).float().to(device))\n",
    "                final_video_prediction = 1 if 1 in torch.max(outputs, 1)[1] else 0\n",
    "            y_pred_final.append(final_video_prediction)\n",
    "    return accuracy_score(long_labels, y_pred_final) * 100\n",
    "\n",
    "print(\"Model architecture, loss functions, and evaluation helpers are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_online_training_trial(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_windowed_loader: DataLoader,\n",
    "    val_long_sequences: list[np.ndarray],\n",
    "    val_long_labels: list[int],\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    num_epochs: int,\n",
    "    model_save_path_window: str,\n",
    "    model_save_path_realistic: str,\n",
    "    device: torch.device\n",
    "):\n",
    "    best_val_acc_window = 0.0\n",
    "    best_val_acc_realistic = 0.0\n",
    "    history = {'train_loss': [], 'val_acc_window': [], 'val_acc_realistic': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} | Training\")\n",
    "        for sequences, labels in train_pbar:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        correct_window, total_window = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_windowed_loader:\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                outputs = model(sequences)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_window += labels.size(0)\n",
    "                correct_window += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_acc_val_window = 100 * correct_window / total_window\n",
    "        history['val_acc_window'].append(epoch_acc_val_window)\n",
    "\n",
    "        epoch_acc_val_realistic = evaluate_realistically(\n",
    "            model, val_long_sequences, val_long_labels, device, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES\n",
    "        )\n",
    "        history['val_acc_realistic'].append(epoch_acc_val_realistic)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Window Val Acc: {epoch_acc_val_window:.2f}% | Realistic Val Acc: {epoch_acc_val_realistic:.2f}%\")\n",
    "\n",
    "        if epoch_acc_val_window > best_val_acc_window:\n",
    "            best_val_acc_window = epoch_acc_val_window\n",
    "            torch.save(model.state_dict(), model_save_path_window)\n",
    "            print(f\" New best WINDOW model saved (Val Acc: {best_val_acc_window:.2f}%)\")\n",
    "\n",
    "        if epoch_acc_val_realistic > best_val_acc_realistic:\n",
    "            best_val_acc_realistic = epoch_acc_val_realistic\n",
    "            torch.save(model.state_dict(), model_save_path_realistic)\n",
    "            print(f\" New best REALISTIC model saved (Val Acc: {best_val_acc_realistic:.2f}%)\")\n",
    "\n",
    "    print(\"\\n Finished Training Trial \")\n",
    "    return history\n",
    "\n",
    "print(\" Trial 1: Training with Standard Cross-Entropy Loss \")\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "X_val_tensor = torch.from_numpy(X_val_windowed).float()\n",
    "y_val_tensor = torch.from_numpy(y_val_windowed).long()\n",
    "val_windowed_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_windowed_loader = DataLoader(val_windowed_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "ce_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "\n",
    "ce_criterion = nn.CrossEntropyLoss()\n",
    "ce_optimizer = optim.Adam(ce_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "ce_model_path_window = 'best_ce_model_window.pth'\n",
    "ce_model_path_realistic = 'best_ce_model_realistic.pth'\n",
    "\n",
    "ce_history = run_online_training_trial(\n",
    "    model=ce_model,\n",
    "    train_loader=train_loader,\n",
    "    val_windowed_loader=val_windowed_loader,\n",
    "    val_long_sequences=X_val_long,\n",
    "    val_long_labels=y_val_long,\n",
    "    criterion=ce_criterion,\n",
    "    optimizer=ce_optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model_save_path_window=ce_model_path_window,\n",
    "    model_save_path_realistic=ce_model_path_realistic,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_history(history: dict, trial_name: str):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Training Loss', color='tab:red')\n",
    "    ax1.plot(history['train_loss'], 'r-', label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "    ax2.plot(history['val_acc_window'], 'b--', label='Window Val Acc')\n",
    "    ax2.plot(history['val_acc_realistic'], 'g-.', label='Realistic Val Acc')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f'{trial_name} - Training History', y=1.03)\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "    plt.show()\n",
    "\n",
    "print(\" Plotting Training History for Trial 1 (Cross-Entropy) \")\n",
    "plot_history(ce_history, \"Cross-Entropy Loss\")\n",
    "\n",
    "print(\"\\n Loading best model for final evaluation on the Test Set \")\n",
    "set_seed(SEED)\n",
    "\n",
    "final_ce_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "final_ce_model.load_state_dict(torch.load(ce_model_path_realistic))\n",
    "print(f\"Model loaded successfully from: {ce_model_path_realistic}\")\n",
    "\n",
    "evaluate_and_report_on_test_set(\n",
    "    model=final_ce_model,\n",
    "    test_sequences=X_test_long,\n",
    "    test_labels=y_test_long,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# --- Plotting Function for Single Windows ---\n",
    "def plot_trajectory_window_on_ax(ax: plt.Axes, csv_path: str, start_frame: int, window_size: int, title: str):\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        ax.set_title(\"File Not Found\")\n",
    "        return\n",
    "    \n",
    "    end_frame = start_frame + window_size\n",
    "    if df.empty or 'POSES' not in df.columns or len(df) < end_frame:\n",
    "        ax.set_title(f\"No data at frame {start_frame}\")\n",
    "        return\n",
    "\n",
    "    raw_poses = np.array(df['POSES'].iloc[start_frame:end_frame].apply(parse_poses_from_string).tolist())\n",
    "    neck_trajectory = raw_poses[:, 1, :]\n",
    "    neck_trajectory = neck_trajectory[np.any(neck_trajectory != 0, axis=1)]\n",
    "\n",
    "    if neck_trajectory.shape[0] > 1:\n",
    "        ax.plot(neck_trajectory[:, 0], neck_trajectory[:, 1], color='red', linewidth=2.5)\n",
    "        ax.plot(neck_trajectory[0, 0], neck_trajectory[0, 1], 'go', markersize=10, label='Start')\n",
    "        ax.plot(neck_trajectory[-1, 0], neck_trajectory[-1, 1], 'ro', markersize=10, label='End')\n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.set_xlabel('x (pixels)')\n",
    "        ax.set_ylabel('y (pixels)')\n",
    "        ax.legend(fontsize='small')\n",
    "    else:\n",
    "        ax.set_title(f\"No valid data in window\\nstarting at frame {start_frame}\")\n",
    "\n",
    "\n",
    "def find_all_failure_windows_in_test_set(model, test_videos, test_labels, test_paths):\n",
    "    \"\"\"\n",
    "    Iterates through the entire test set, finds every misclassified window,\n",
    "    and returns them categorized as False Positives or False Negatives.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    fp_windows = [] # List to store (csv_path, start_frame)\n",
    "    fn_windows = [] # List to store (csv_path, start_frame)\n",
    "\n",
    "    print(f\"Analyzing {len(test_videos)} videos in the test set...\")\n",
    "    \n",
    "    # Iterate through each video in the test set\n",
    "    for video_idx, video_data in enumerate(test_videos):\n",
    "        true_label = test_labels[video_idx]\n",
    "        csv_path = test_paths[video_idx]\n",
    "        \n",
    "        # Iterate through the windows of the current video\n",
    "        for start in range(0, video_data.shape[0] - WINDOW_SIZE_FRAMES + 1, STEP_SIZE_FRAMES):\n",
    "            # The `video_data` is already the feature-extracted numpy array\n",
    "            feature_window = video_data[start : start + WINDOW_SIZE_FRAMES]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                input_tensor = torch.from_numpy(feature_window).unsqueeze(0).float().to(device)\n",
    "                output = model(input_tensor)\n",
    "                prediction = torch.max(output, 1)[1].item()\n",
    "            \n",
    "            if prediction != true_label:\n",
    "                window_info = (csv_path, start)\n",
    "                if true_label == 0: # False Positive\n",
    "                    fp_windows.append(window_info)\n",
    "                else: # False Negative\n",
    "                    fn_windows.append(window_info)\n",
    "                    \n",
    "    return fp_windows, fn_windows\n",
    "\n",
    "print(\"\\n--- Finding All Misclassified Windows in the Test Set ---\")\n",
    "fp_windows, fn_windows = find_all_failure_windows_in_test_set(\n",
    "    final_ce_model, X_test_long, y_test_long, test_paths_long\n",
    ")\n",
    "print(f\"Found {len(fp_windows)} total False Positive windows across all 'Normal' videos.\")\n",
    "print(f\"Found {len(fn_windows)} total False Negative windows across all 'Shoplifter' videos.\")\n",
    "\n",
    "if not fp_windows and not fn_windows:\n",
    "    print(\"\\nExcellent! No misclassified windows found anywhere in the test set.\")\n",
    "else:\n",
    "    num_rows = max(len(fp_windows), len(fn_windows))\n",
    "    fig, axes = plt.subplots(num_rows, 2, figsize=(16, 6 * num_rows), squeeze=False)\n",
    "    fig.suptitle(\"Comprehensive Analysis of All Misclassified Windows in Test Set\", fontsize=20, y=0.99)\n",
    "\n",
    "    axes[0, 0].set_title(\"False Positives\\n(Normal Windows -> Predicted Shoplifter)\", fontsize=16, pad=25)\n",
    "    axes[0, 1].set_title(\"False Negatives\\n(Shoplifter Windows -> Predicted Normal)\", fontsize=16, pad=25)\n",
    "\n",
    "    # Plot all False Positive windows\n",
    "    for i in range(num_rows):\n",
    "        ax = axes[i, 0]\n",
    "        if i < len(fp_windows):\n",
    "            csv_path, start_frame = fp_windows[i]\n",
    "            title = f\"{os.path.basename(csv_path)}\\n(Frames {start_frame}-{start_frame+WINDOW_SIZE_FRAMES})\"\n",
    "            plot_trajectory_window_on_ax(ax, csv_path, start_frame, WINDOW_SIZE_FRAMES, title)\n",
    "        else:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "    # Plot all False Negative windows\n",
    "    for i in range(num_rows):\n",
    "        ax = axes[i, 1]\n",
    "        if i < len(fn_windows):\n",
    "            csv_path, start_frame = fn_windows[i]\n",
    "            title = f\"{os.path.basename(csv_path)}\\n(Frames {start_frame}-{start_frame+WINDOW_SIZE_FRAMES})\"\n",
    "            plot_trajectory_window_on_ax(ax, csv_path, start_frame, WINDOW_SIZE_FRAMES, title)\n",
    "        else:\n",
    "            ax.set_visible(False)\n",
    "            \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\" Trial 2: Training with Focal Loss \")\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "focal_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "\n",
    "total_videos = 88 + 64\n",
    "alpha_class_0 = 64 / total_videos\n",
    "alpha_class_1 = 88 / total_videos\n",
    "alpha_tensor = torch.tensor([alpha_class_0, alpha_class_1]).to(device)\n",
    "\n",
    "print(f\"Calculated alpha weights for Focal Loss: {alpha_tensor.cpu().numpy()}\")\n",
    "\n",
    "focal_criterion = FocalLoss(alpha=alpha_tensor, gamma=3.0)\n",
    "focal_optimizer = optim.AdamW(focal_model.parameters(), lr=0.00001, weight_decay=1e-4)\n",
    "\n",
    "focal_model_path_window = 'best_focal_model_window.pth'\n",
    "focal_model_path_realistic = 'best_focal_model_realistic.pth'\n",
    "\n",
    "focal_history = run_online_training_trial(\n",
    "    model=focal_model,\n",
    "    train_loader=train_loader,\n",
    "    val_windowed_loader=val_windowed_loader,\n",
    "    val_long_sequences=X_val_long,\n",
    "    val_long_labels=y_val_long,\n",
    "    criterion=focal_criterion,\n",
    "    optimizer=focal_optimizer,\n",
    "    num_epochs=50, #NUM_EPOCHS\n",
    "    model_save_path_window=focal_model_path_window,\n",
    "    model_save_path_realistic=focal_model_path_realistic,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_model_predictions_for_test_set(model: nn.Module, test_sequences: list, test_labels: list, device: torch.device) -> list:\n",
    "    model.eval()\n",
    "    video_suspicion_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for long_seq_np in test_sequences:\n",
    "            seq_windows_tensors = []\n",
    "            if long_seq_np.shape[0] >= WINDOW_SIZE_FRAMES:\n",
    "                for start in range(0, long_seq_np.shape[0] - WINDOW_SIZE_FRAMES + 1, STEP_SIZE_FRAMES):\n",
    "                    window = long_seq_np[start:start + WINDOW_SIZE_FRAMES]\n",
    "                    seq_windows_tensors.append(torch.from_numpy(window))\n",
    "            if not seq_windows_tensors:\n",
    "                video_suspicion_scores.append(0.0)\n",
    "                continue\n",
    "            windows_batch = torch.stack(seq_windows_tensors).float().to(device)\n",
    "            outputs = model(windows_batch)\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            avg_suspicion_score = probabilities.mean().item()\n",
    "            video_suspicion_scores.append(avg_suspicion_score)\n",
    "\n",
    "    precisions, recalls, thresholds = precision_recall_curve(test_labels, video_suspicion_scores)\n",
    "    f1_scores = np.nan_to_num(2 * (precisions * recalls) / (precisions + recalls))\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    y_pred_thresholded = [1 if score >= best_threshold else 0 for score in video_suspicion_scores]\n",
    "    return y_pred_thresholded\n",
    "\n",
    "print(\" Plotting Training History for Trial 2 (Focal Loss) \")\n",
    "plot_history(focal_history, \"Focal Loss\")\n",
    "\n",
    "print(\"\\n Loading best Focal Loss model for final evaluation on the Test Set \")\n",
    "set_seed(SEED)\n",
    "\n",
    "final_focal_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "final_focal_model.load_state_dict(torch.load(focal_model_path_realistic))\n",
    "print(f\"Model loaded successfully from: {focal_model_path_realistic}\")\n",
    "\n",
    "evaluate_and_report_on_test_set(\n",
    "    model=final_focal_model,\n",
    "    test_sequences=X_test_long,\n",
    "    test_labels=y_test_long,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\n Visualizing Failure Cases for Trial 2 (Focal Loss) \")\n",
    "\n",
    "focal_test_predictions = get_model_predictions_for_test_set(final_focal_model, X_test_long, y_test_long, device)\n",
    "focal_failure_indices = [i for i, (pred, true) in enumerate(zip(focal_test_predictions, y_test_long)) if pred != true]\n",
    "fn_failures_focal = [i for i in focal_failure_indices if y_test_long[i] == 1]\n",
    "fp_failures_focal = [i for i in focal_failure_indices if y_test_long[i] == 0]\n",
    "\n",
    "print(f\"Identified {len(focal_failure_indices)} total failure cases for the Focal Loss model.\")\n",
    "print(f\" - {len(fn_failures_focal)} False Negatives (Missed Shoplifters)\")\n",
    "print(f\" - {len(fp_failures_focal)} False Positives (Incorrectly Flagged Normals)\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8036220,
     "sourceId": 12714869,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
