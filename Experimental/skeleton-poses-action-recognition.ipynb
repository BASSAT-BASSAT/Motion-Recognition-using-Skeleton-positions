{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "print(\"All necessary libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "WINDOW_SIZE_FRAMES = 150\n",
    "STEP_SIZE_FRAMES = 30\n",
    "BATCH_SIZE = 128\n",
    "INPUT_FEATURES = 73\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 10\n",
    "def set_seed(seed_value: int):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Global seed set to {seed_value}\")\n",
    "def load_and_label_files(data_root: str) -> pd.DataFrame:\n",
    "    all_csv_files = glob(os.path.join(data_root, '**', '*.csv'), recursive=True)\n",
    "    labeled_data = [{'path': file_path, 'label': 1 if 'Potential_shoplifter' in file_path else 0} for file_path in all_csv_files]\n",
    "    df_files = pd.DataFrame(labeled_data)\n",
    "    print(f\"Found {len(df_files)} total CSV files.\")\n",
    "    if not df_files.empty:\n",
    "        print(\"\\nValue counts for labels:\")\n",
    "        print(df_files['label'].value_counts())\n",
    "    return df_files\n",
    "def parse_poses_from_string(poses_str: str) -> np.ndarray:\n",
    "    try:\n",
    "        return np.array(json.loads(poses_str)).reshape(18, 2)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return np.zeros((18, 2))\n",
    "def extract_features(csv_path: str) -> np.ndarray | None:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if df.empty or 'POSES' not in df.columns:\n",
    "        return None\n",
    "    raw_poses = np.array(df['POSES'].apply(parse_poses_from_string).tolist())\n",
    "    neck_positions = raw_poses[:, 1:2, :]\n",
    "    normalized_poses = raw_poses - neck_positions\n",
    "    velocities = np.diff(raw_poses, axis=0, prepend=raw_poses[0:1])\n",
    "    neck_trajectory = raw_poses[:, 1, :]\n",
    "    deltas = np.diff(neck_trajectory, axis=0, prepend=[neck_trajectory[0]])\n",
    "    orientation_angles_deg = np.degrees(np.arctan2(deltas[:, 1], deltas[:, 0]))\n",
    "    return np.concatenate([\n",
    "        normalized_poses.reshape(raw_poses.shape[0], -1),\n",
    "        velocities.reshape(raw_poses.shape[0], -1),\n",
    "        orientation_angles_deg.reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "set_seed(SEED)\n",
    "print(f\"Using device: {device}\")\n",
    "data_root = '/kaggle/input/skeleton-poses-normalvsshoplifter/csvs_Skeleton_poses_normal_potential_shoplifter/'\n",
    "df_files = load_and_label_files(data_root)\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_id(file_path: str) -> str:\n",
    "    return os.path.basename(file_path).replace('.csv', '')[-23:]\n",
    "def create_sliding_windows(sequences: list, labels: list, window_size: int, step_size: int):\n",
    "    windowed_sequences, windowed_labels = [], []\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if seq.shape[0] >= window_size:\n",
    "            for start in range(0, seq.shape[0] - window_size + 1, step_size):\n",
    "                windowed_sequences.append(seq[start:start + window_size])\n",
    "                windowed_labels.append(labels[i])\n",
    "    return np.array(windowed_sequences), np.array(windowed_labels)\n",
    "print(\"Processing all CSV files into feature sequences\")\n",
    "all_sequences, all_labels, all_groups, all_paths = [], [], [], []\n",
    "for _, row in tqdm(df_files.iterrows(), total=len(df_files), desc=\"Extracting Features\"):\n",
    "    features = extract_features(row['path'])\n",
    "    if features is not None and len(features) > 0:\n",
    "        all_sequences.append(features)\n",
    "        all_labels.append(row['label'])\n",
    "        all_groups.append(get_group_id(row['path']))\n",
    "        all_paths.append(row['path'])\n",
    "print(\"\\nSplitting data by group to prevent leakage\")\n",
    "gss_train_temp = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_group_indices, temp_group_indices = next(gss_train_temp.split(all_sequences, all_labels, all_groups))\n",
    "train_sequences = [all_sequences[i] for i in train_group_indices]\n",
    "train_labels = [all_labels[i] for i in train_group_indices]\n",
    "temp_sequences = [all_sequences[i] for i in temp_group_indices]\n",
    "temp_labels = [all_labels[i] for i in temp_group_indices]\n",
    "temp_groups = np.array(all_groups)[temp_group_indices]\n",
    "temp_paths = [all_paths[i] for i in temp_group_indices]\n",
    "print(\"\\nCreating datasets: augmented for training, and both windowed & full-length for val/test\")\n",
    "X_train_windowed, y_train_windowed = create_sliding_windows(train_sequences, train_labels, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "gss_val_test = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "val_indices, test_indices = next(gss_val_test.split(temp_sequences, temp_labels, temp_groups))\n",
    "X_val_long = [temp_sequences[i] for i in val_indices]\n",
    "y_val_long = [temp_labels[i] for i in val_indices]\n",
    "X_test_long = [temp_sequences[i] for i in test_indices]\n",
    "y_test_long = [temp_labels[i] for i in test_indices]\n",
    "test_paths_long = [temp_paths[i] for i in test_indices]\n",
    "X_val_windowed, y_val_windowed = create_sliding_windows(X_val_long, y_val_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "X_test_windowed, y_test_windowed = create_sliding_windows(X_test_long, y_test_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "X_train_tensor = torch.from_numpy(X_train_windowed).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_windowed).long()\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=g)\n",
    "print(\"\\nData Preparation Complete\")\n",
    "print(f\"Total original videos processed: {len(all_sequences)}\")\n",
    "print(f\"Training on {len(X_train_tensor)} augmented windows (from {len(train_sequences)} videos).\")\n",
    "print(f\"Validating on {len(X_val_long)} full-length videos.\")\n",
    "print(f\"Testing on {len(X_test_long)} full-length videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.5):\n",
    "        super(RealTimeClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out, _ = self.lstm(x)\n",
    "        attention_scores = self.attention(out)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        context_vector = torch.sum(attention_weights * out, dim=1)\n",
    "        context_vector_dropped = self.dropout(context_vector)\n",
    "        return self.fc(context_vector_dropped)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 2.0, reduction: str = 'mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.alpha[targets] * (1 - pt)**self.gamma * ce_loss)\n",
    "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()\n",
    "def evaluate_and_report_on_test_set(\n",
    "    model: nn.Module,\n",
    "    test_sequences: list[np.ndarray],\n",
    "    test_labels: list[int],\n",
    "    device: torch.device\n",
    "):\n",
    "    model.eval()\n",
    "    all_window_preds, all_window_labels = [], []\n",
    "    video_suspicion_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, long_seq_np in enumerate(tqdm(test_sequences, desc=\"Evaluating Test Set\")):\n",
    "            y_true_video = test_labels[i]\n",
    "            seq_windows_tensors = []\n",
    "            if long_seq_np.shape[0] >= WINDOW_SIZE_FRAMES:\n",
    "                for start in range(0, long_seq_np.shape[0] - WINDOW_SIZE_FRAMES + 1, STEP_SIZE_FRAMES):\n",
    "                    window = long_seq_np[start:start + WINDOW_SIZE_FRAMES]\n",
    "                    seq_windows_tensors.append(torch.from_numpy(window))\n",
    "            \n",
    "            if not seq_windows_tensors:\n",
    "                video_suspicion_scores.append(0.0)\n",
    "                continue\n",
    "\n",
    "            windows_batch = torch.stack(seq_windows_tensors).float().to(device)\n",
    "            outputs = model(windows_batch)\n",
    "            \n",
    "            _, predicted_windows = torch.max(outputs, 1)\n",
    "            all_window_preds.extend(predicted_windows.cpu().numpy())\n",
    "            all_window_labels.extend([y_true_video] * len(predicted_windows))\n",
    "            \n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            avg_suspicion_score = probabilities.mean().item()\n",
    "            video_suspicion_scores.append(avg_suspicion_score)\n",
    "\n",
    "    plot_report_and_matrix(all_window_labels, all_window_preds, \"Test Set Evaluation (Per-Window)\")\n",
    "    simple_accuracy = evaluate_realistically(model, test_sequences, test_labels, device, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "    print(f\"\\n--- Test Set Evaluation (Simple Per-Video) ---\")\n",
    "    print(f\"Accuracy (if any window is 1, predict 1): {simple_accuracy:.2f}%\")\n",
    "\n",
    "    y_true_video_labels = test_labels\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_video_labels, video_suspicion_scores)\n",
    "    f1_scores = np.nan_to_num(2 * (precisions * recalls) / (precisions + recalls))\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    \n",
    "    y_pred_thresholded = [1 if score >= best_threshold else 0 for score in video_suspicion_scores]\n",
    "    plot_report_and_matrix(y_true_video_labels, y_pred_thresholded, f\"Test Set Evaluation (Optimal Threshold: {best_threshold:.2f})\")\n",
    "\n",
    "def plot_report_and_matrix(y_true, y_pred, title):\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Normal', 'Potential Shoplifter'], zero_division=0))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Normal', 'Potential Shoplifter'], yticklabels=['Normal', 'Potential Shoplifter'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_realistically(model, long_sequences, long_labels, device, window_size, step_size):\n",
    "    model.eval()\n",
    "    y_pred_final = []\n",
    "    with torch.no_grad():\n",
    "        for long_seq_np in long_sequences:\n",
    "            seq_windows_tensors = []\n",
    "            if long_seq_np.shape[0] >= window_size:\n",
    "                for start in range(0, long_seq_np.shape[0] - window_size + 1, step_size):\n",
    "                    seq_windows_tensors.append(torch.from_numpy(long_seq_np[start:start + window_size]))\n",
    "            \n",
    "            if not seq_windows_tensors:\n",
    "                final_video_prediction = 0\n",
    "            else:\n",
    "                outputs = model(torch.stack(seq_windows_tensors).float().to(device))\n",
    "                final_video_prediction = 1 if 1 in torch.max(outputs, 1)[1] else 0\n",
    "            y_pred_final.append(final_video_prediction)\n",
    "    return accuracy_score(long_labels, y_pred_final) * 100\n",
    "\n",
    "print(\"Model architecture, loss functions, and evaluation helpers are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_online_training_trial(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_windowed_loader: DataLoader,\n",
    "    val_long_sequences: list[np.ndarray],\n",
    "    val_long_labels: list[int],\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    num_epochs: int,\n",
    "    model_save_path_window: str,\n",
    "    model_save_path_realistic: str,\n",
    "    device: torch.device\n",
    "):\n",
    "    best_val_acc_window = 0.0\n",
    "    best_val_acc_realistic = 0.0\n",
    "\n",
    "    history = {'train_loss': [], 'val_acc_window': [], 'val_acc_realistic': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} | Training\")\n",
    "        for sequences, labels in train_pbar:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        correct_window, total_window = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_windowed_loader:\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                outputs = model(sequences)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_window += labels.size(0)\n",
    "                correct_window += (predicted == labels).sum().item()\n",
    "        epoch_acc_val_window = 100 * correct_window / total_window\n",
    "        history['val_acc_window'].append(epoch_acc_val_window)\n",
    "\n",
    "        epoch_acc_val_realistic = evaluate_realistically(\n",
    "            model, val_long_sequences, val_long_labels, device, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES\n",
    "        )\n",
    "        history['val_acc_realistic'].append(epoch_acc_val_realistic)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Window Val Acc: {epoch_acc_val_window:.2f}% | \"\n",
    "              f\"Realistic Val Acc: {epoch_acc_val_realistic:.2f}%\")\n",
    "        \n",
    "        if epoch_acc_val_window > best_val_acc_window:\n",
    "            best_val_acc_window = epoch_acc_val_window\n",
    "            torch.save(model.state_dict(), model_save_path_window)\n",
    "            print(f\"---> New best WINDOW model saved (Val Acc: {best_val_acc_window:.2f}%)\")\n",
    "            \n",
    "        if epoch_acc_val_realistic > best_val_acc_realistic:\n",
    "            best_val_acc_realistic = epoch_acc_val_realistic\n",
    "            torch.save(model.state_dict(), model_save_path_realistic)\n",
    "            print(f\"---> New best REALISTIC model saved (Val Acc: {best_val_acc_realistic:.2f}%)\")\n",
    "            \n",
    "    print(\"\\n--- Finished Training Trial ---\")\n",
    "    return history\n",
    "\n",
    "print(\"Trial 1: Training with Standard CrossEntropy Loss\")\n",
    "set_seed(SEED)\n",
    "\n",
    "ce_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "\n",
    "ce_criterion = nn.CrossEntropyLoss()\n",
    "ce_optimizer = optim.Adam(ce_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "ce_model_path_window = 'best_ce_model_window.pth'\n",
    "ce_model_path_realistic = 'best_ce_model_realistic.pth'\n",
    "\n",
    "ce_history = run_online_training_trial(\n",
    "    model=ce_model,\n",
    "    train_loader=train_loader,\n",
    "    val_windowed_loader=val_windowed_loader,\n",
    "    val_long_sequences=X_val_long,\n",
    "    val_long_labels=y_val_long,\n",
    "    criterion=ce_criterion,\n",
    "    optimizer=ce_optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model_save_path_window=ce_model_path_window,\n",
    "    model_save_path_realistic=ce_model_path_realistic,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: dict, trial_name: str):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Training Loss', color='tab:red')\n",
    "    ax1.plot(history['train_loss'], 'r-', label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "    ax2.plot(history['val_acc_window'], 'b--', label='Window Val Acc')\n",
    "    ax2.plot(history['val_acc_realistic'], 'g-.', label='Realistic Val Acc')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f'{trial_name} - Training History', y=1.03)\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "    plt.show()\n",
    "\n",
    "print(\"Plotting Training History for Trial 1 (CrossEntropy)\")\n",
    "plot_history(ce_history, \"CrossEntropy Loss\")\n",
    "\n",
    "print(\"\\nLoading best model for final evaluation on the Test Set\")\n",
    "set_seed(SEED)\n",
    "final_ce_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "final_ce_model.load_state_dict(torch.load(ce_model_path_realistic))\n",
    "print(f\"Model loaded successfully from: {ce_model_path_realistic}\")\n",
    "\n",
    "evaluate_and_report_on_test_set(\n",
    "    model=final_ce_model,\n",
    "    test_sequences=X_test_long,\n",
    "    test_labels=y_test_long,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading best model optimized for perwindow performance\")\n",
    "set_seed(SEED)\n",
    "\n",
    "window_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "window_model.load_state_dict(torch.load(ce_model_path_window)) \n",
    "window_model.eval()\n",
    "\n",
    "all_window_preds = []\n",
    "_, y_test_windowed_labels, test_window_source_indices = create_sliding_windows_with_indices(\n",
    "    X_test_long, y_test_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, _ in tqdm(test_windowed_loader, desc=\"Getting Per-Window Predictions\"):\n",
    "        outputs = window_model(sequences.to(device))\n",
    "        all_window_preds.extend(torch.max(outputs.data, 1)[1].cpu().numpy())\n",
    "\n",
    "fn_video_indices = set()\n",
    "fp_video_indices = set()\n",
    "\n",
    "for i, (pred, true) in enumerate(zip(all_window_preds, y_test_windowed_labels)):\n",
    "    if pred != true:\n",
    "        source_idx = test_window_source_indices[i]\n",
    "        if true == 1:\n",
    "            fn_video_indices.add(source_idx)\n",
    "        else:\n",
    "            fp_video_indices.add(source_idx)\n",
    "\n",
    "print(f\"\\nIdentified {len(fn_video_indices)} videos with Shoplifter misclassifications.\")\n",
    "print(f\"Identified {len(fp_video_indices)} videos with Normal Pedestrian misclassifications.\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Fig 9. Samples from failure cases', fontsize=18, y=0.95)\n",
    "\n",
    "fn_indices_list = list(fn_video_indices)\n",
    "axes[0, 0].set_title('Shoplifter Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 0]):\n",
    "    if i < len(fn_indices_list):\n",
    "        idx = fn_indices_list[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "fp_indices_list = list(fp_video_indices)\n",
    "axes[0, 1].set_title('Normal Pedestrian Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 1]):\n",
    "    if i < len(fp_indices_list):\n",
    "        idx = fp_indices_list[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Trial 2: Training with Focal Loss \")\n",
    "set_seed(SEED)\n",
    "\n",
    "focal_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "\n",
    "alpha_class_0 = 64 / total_videos\n",
    "alpha_class_1 = 88 / total_videos\n",
    "alpha_tensor = torch.tensor([alpha_class_0, alpha_class_1]).to(device)\n",
    "\n",
    "print(f\"Calculated alpha weights for Focal Loss: {alpha_tensor.cpu().numpy()}\")\n",
    "\n",
    "focal_criterion = FocalLoss(alpha=alpha_tensor, gamma=2.0)\n",
    "focal_optimizer = optim.Adam(focal_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "focal_model_path_window = 'best_focal_model_window.pth'\n",
    "focal_model_path_realistic = 'best_focal_model_realistic.pth'\n",
    "\n",
    "focal_history = run_online_training_trial(\n",
    "    model=focal_model,\n",
    "    train_loader=train_loader,\n",
    "    val_windowed_loader=val_windowed_loader,\n",
    "    val_long_sequences=X_val_long,\n",
    "    val_long_labels=y_val_long,\n",
    "    criterion=focal_criterion,\n",
    "    optimizer=focal_optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model_save_path_window=focal_model_path_window,\n",
    "    model_save_path_realistic=focal_model_path_realistic,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Plotting Training History for Trial 2 (Focal Loss) \")\n",
    "plot_history(focal_history, \"Focal Loss\")\n",
    "\n",
    "print(\"\\n--- Loading best Focal Loss model for final evaluation on the Test Set ---\")\n",
    "set_seed(SEED)\n",
    "final_focal_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "final_focal_model.load_state_dict(torch.load(focal_model_path_realistic))\n",
    "print(f\"Model loaded successfully from: {focal_model_path_realistic}\")\n",
    "\n",
    "evaluate_and_report_on_test_set(\n",
    "    model=final_focal_model,\n",
    "    test_sequences=X_test_long,\n",
    "    test_labels=y_test_long,\n",
    "    device=device\n",
    ")\n",
    "print(\"\\nVisualizing Failure Cases for Trial 2 (Focal Loss)\")\n",
    "focal_test_predictions = get_model_predictions_for_test_set(final_focal_model, X_test_long, y_test_long, device)\n",
    "focal_failure_indices = [i for i, (pred, true) in enumerate(zip(focal_test_predictions, y_test_long)) if pred != true]\n",
    "fn_failures_focal = [i for i in focal_failure_indices if y_test_long[i] == 1]\n",
    "fp_failures_focal = [i for i in focal_failure_indices if y_test_long[i] == 0]\n",
    "print(f\"Identified {len(focal_failure_indices)} total failure cases for the Focal Loss model.\")\n",
    "print(f\" {len(fn_failures_focal)} False Negatives (Missed Shoplifters)\")\n",
    "print(f\" {len(fp_failures_focal)} False Positives (Incorrectly Flagged Normals)\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Fig 9. Samples from failure cases (Focal Loss Model)', fontsize=18, y=0.95)\n",
    "fn_indices_list_focal = list(fn_failures_focal)\n",
    "axes[0, 0].set_title('UroKyoro Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 0]):\n",
    "    if i < len(fn_indices_list_focal):\n",
    "        idx = fn_indices_list_focal[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "fp_indices_list_focal = list(fp_failures_focal)\n",
    "axes[0, 1].set_title('Normal Pedestrian Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 1]):\n",
    "    if i < len(fp_indices_list_focal):\n",
    "        idx = fp_indices_list_focal[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch_geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "\n",
    "print(\"PyTorch Geometric and its dependencies have been installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"--- Imports for Graph Convolutional Network (GCN) Approach ---\")\n",
    "\n",
    "# --- Configuration & Seeding ---\n",
    "SEED = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model and training constants\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "# We will define other model-specific constants later\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    \"\"\"Sets the seed for reproducibility for all relevant libraries.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Global seed set to {seed_value}\")\n",
    "\n",
    "# --- Execute ---\n",
    "set_seed(SEED)\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"All necessary libraries and configurations are set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FRAMES = 300\n",
    "\n",
    "edge_index = torch.tensor([\n",
    "    # Torso\n",
    "    [1, 2], [1, 5], [2, 8], [5, 11], [8, 11], [1, 0],\n",
    "    # Left Arm\n",
    "    [2, 3], [3, 4],\n",
    "    # Right Arm\n",
    "    [5, 6], [6, 7],\n",
    "    # Left Leg\n",
    "    [8, 9], [9, 10],\n",
    "    # Right Leg\n",
    "    [11, 12], [12, 13]\n",
    "], dtype=torch.long).t().contiguous()\n",
    "\n",
    "def load_and_label_files(data_root: str) -> pd.DataFrame:\n",
    "    \"\"\"Finds all CSVs, labels them based on the folder, and returns a DataFrame.\"\"\"\n",
    "    all_csv_files = glob(os.path.join(data_root, '**', '*.csv'), recursive=True)\n",
    "    labeled_data = [{'path': file_path, 'label': 1 if 'Potential_shoplifter' in file_path else 0} for file_path in all_csv_files]\n",
    "    df_files = pd.DataFrame(labeled_data)\n",
    "    print(f\"Found {len(df_files)} total CSV files.\")\n",
    "    return df_files\n",
    "\n",
    "def parse_poses_from_string(poses_str: str) -> np.ndarray:\n",
    "    \"\"\"Helper to parse the 'POSES' string into a numpy array.\"\"\"\n",
    "    try:\n",
    "        return np.array(json.loads(poses_str)).reshape(18, 2)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return np.zeros((18, 2))\n",
    "\n",
    "\n",
    "class SkeletonDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Geometric Dataset for loading skeleton action recognition data.\n",
    "    Each video is represented as a single graph.\n",
    "    - Nodes: The 18 skeleton joints.\n",
    "    - Node Features: The flattened (x, y) coordinates of each joint across all frames.\n",
    "    - Edges: The predefined bone connections.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, max_frames: int):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.max_frames = max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        csv_path = row['path']\n",
    "        label = row['label']\n",
    "\n",
    "        # Load and parse pose data from the CSV\n",
    "        df_poses = pd.read_csv(csv_path)\n",
    "        raw_poses = np.array(df_poses['POSES'].apply(parse_poses_from_string).tolist()) # Shape: (n_frames, 18, 2)\n",
    "\n",
    "        # --- Temporal Padding/Truncating ---\n",
    "        n_frames = raw_poses.shape[0]\n",
    "        if n_frames < self.max_frames:\n",
    "            # Pad with zeros if the sequence is too short\n",
    "            padding = np.zeros((self.max_frames - n_frames, 18, 2))\n",
    "            processed_poses = np.concatenate([raw_poses, padding], axis=0)\n",
    "        else:\n",
    "            # Truncate if the sequence is too long\n",
    "            processed_poses = raw_poses[:self.max_frames, :, :]\n",
    "\n",
    "        # --- Feature Engineering ---\n",
    "        # The feature for each node (joint) is its entire trajectory.\n",
    "        # Reshape to (num_nodes, features_per_node) where features are (max_frames * 2)\n",
    "        node_features = torch.tensor(processed_poses.transpose(1, 0, 2).reshape(18, -1), dtype=torch.float)\n",
    "\n",
    "        # Create the graph data object\n",
    "        data = Data(\n",
    "            x=node_features,         # Node features: Shape [18, max_frames * 2]\n",
    "            edge_index=edge_index,   # Graph connectivity\n",
    "            y=torch.tensor([label], dtype=torch.long) # Label\n",
    "        )\n",
    "        return data\n",
    "\n",
    "data_root = '/kaggle/input/skeleton-poses-normalvsshoplifter/csvs_Skeleton_poses_normal_potential_shoplifter/'\n",
    "df_files = load_and_label_files(data_root)\n",
    "full_dataset = SkeletonDataset(df=df_files, max_frames=MAX_FRAMES)\n",
    "\n",
    "print(f\"\\nSuccessfully created a dataset with {len(full_dataset)} graphs.\")\n",
    "print(\"\\nExample of a single graph data object from the dataset:\")\n",
    "print(full_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "def get_group_id(file_path: str) -> str:\n",
    "    return os.path.basename(file_path).replace('.csv', '')[-23:]\n",
    "groups = [get_group_id(path) for path in df_files['path']]\n",
    "labels = df_files['label'].values\n",
    "indices = np.arange(len(full_dataset))\n",
    "gss_train_temp = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_indices, temp_indices = next(gss_train_temp.split(indices, labels, groups))\n",
    "gss_val_test = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "val_indices, test_indices = next(gss_val_test.split(\n",
    "    indices[temp_indices],\n",
    "    labels[temp_indices],\n",
    "    np.array(groups)[temp_indices]\n",
    "))\n",
    "final_val_indices = temp_indices[val_indices]\n",
    "final_test_indices = temp_indices[test_indices]\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, final_val_indices)\n",
    "test_dataset = Subset(full_dataset, final_test_indices)\n",
    "train_loader = PyGDataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = PyGDataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = PyGDataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"--- Data Splitting and DataLoader Creation Complete ---\")\n",
    "print(f\"Total graphs: {len(full_dataset)}\")\n",
    "print(f\"Training graphs: {len(train_dataset)}\")\n",
    "print(f\"Validation graphs: {len(val_dataset)}\")\n",
    "print(f\"Testing graphs: {len(test_dataset)}\")\n",
    "print(f\"\\nCreated PyG DataLoaders with batch size {BATCH_SIZE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "class SkeletonGCN(nn.Module):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(SEED)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x_pooled = global_mean_pool(x, batch)\n",
    "        out = self.classifier(x_pooled)\n",
    "        return out\n",
    "model = SkeletonGCN(\n",
    "    in_channels=MAX_FRAMES * 2,\n",
    "    hidden_channels=128,\n",
    "    out_channels=2\n",
    ").to(device)\n",
    "print(\"--- GCN Model Architecture ---\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_gcn(\n",
    "    model: nn.Module,\n",
    "    loader: PyGDataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(loader, desc=\"Training\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "def evaluate_gcn(\n",
    "    model: nn.Module,\n",
    "    loader: PyGDataLoader\n",
    ") -> tuple[float, list, list]:\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=\"Evaluating\"):\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    return accuracy, all_preds, all_labels\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(\"Training and evaluation functions are defined.\")\n",
    "print(\"Criterion: CrossEntropyLoss\")\n",
    "print(\"Optimizer: Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = 0.0\n",
    "model_save_path = 'best_gcn_model.pth'\n",
    "history = {'train_loss': [], 'val_acc': []}\n",
    "print(\"--- Starting GCN Model Training ---\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_one_epoch_gcn(model, train_loader, optimizer, criterion)\n",
    "    val_accuracy, _, _ = evaluate_gcn(model, val_loader)\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_accuracy)\n",
    "    print(f\"Epoch: {epoch:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_accuracy:.2f}% | \"\n",
    "          f\"Duration: {epoch_duration:.2f}s\")\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"==> New best model saved with Val Acc: {best_val_accuracy:.2f}%\")\n",
    "print(\"\\n--- Finished Training ---\")\n",
    "print(f\"The best model was saved to '{model_save_path}' with a validation accuracy of {best_val_accuracy:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gcn_history(history: dict):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Training Loss', color='tab:red')\n",
    "    ax1.plot(history['train_loss'], 'r-', label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "    ax2.plot(history['val_acc'], 'b--', label='Validation Acc')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax2.set_ylim(0, 105)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('GCN Model - Training History', y=1.03)\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "    plt.show()\n",
    "print(\"--- Plotting GCN Training History ---\")\n",
    "plot_gcn_history(history)\n",
    "print(\"\\n--- Loading best model for final evaluation on the Test Set ---\")\n",
    "final_model = SkeletonGCN(\n",
    "    in_channels=MAX_FRAMES * 2,\n",
    "    hidden_channels=128,\n",
    "    out_channels=2\n",
    ").to(device)\n",
    "final_model.load_state_dict(torch.load(model_save_path))\n",
    "print(f\"Model loaded successfully from: {model_save_path}\")\n",
    "test_accuracy, test_preds, test_labels = evaluate_gcn(final_model, test_loader)\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.2f}%\")\n",
    "plot_report_and_matrix(\n",
    "    y_true=test_labels,\n",
    "    y_pred=test_preds,\n",
    "    title=\"GCN Final Test Set Performance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"All necessary libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration & Seeding ---\n",
    "SEED = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Constants for the model and data processing\n",
    "WINDOW_SIZE_FRAMES = 150\n",
    "STEP_SIZE_FRAMES = 30\n",
    "BATCH_SIZE = 128\n",
    "INPUT_FEATURES = 73  # 36 (positions) + 36 (velocities) + 1 (orientation)\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 10 # We'll use 10 epochs for a balance of training and speed\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    \"\"\"Sets the seed for reproducibility for all relevant libraries.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Global seed set to {seed_value}\")\n",
    "\n",
    "# --- Data Handling Functions ---\n",
    "def load_and_label_files(data_root: str) -> pd.DataFrame:\n",
    "    \"\"\"Finds all CSVs, labels them, and returns a DataFrame.\"\"\"\n",
    "    all_csv_files = glob(os.path.join(data_root, '**', '*.csv'), recursive=True)\n",
    "    labeled_data = [{'path': file_path, 'label': 1 if 'Potential_shoplifter' in file_path else 0} for file_path in all_csv_files]\n",
    "    df_files = pd.DataFrame(labeled_data)\n",
    "    print(f\"Found {len(df_files)} total CSV files.\")\n",
    "    if not df_files.empty:\n",
    "        print(\"\\nValue counts for labels:\")\n",
    "        print(df_files['label'].value_counts())\n",
    "    return df_files\n",
    "\n",
    "def parse_poses_from_string(poses_str: str) -> np.ndarray:\n",
    "    \"\"\"Helper function to parse the 'POSES' string into a numpy array.\"\"\"\n",
    "    try:\n",
    "        return np.array(json.loads(poses_str)).reshape(18, 2)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return np.zeros((18, 2))\n",
    "\n",
    "def extract_features(csv_path: str) -> np.ndarray | None:\n",
    "    \"\"\"Reads a CSV and extracts a sequence of feature vectors.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if df.empty or 'POSES' not in df.columns:\n",
    "        return None\n",
    "\n",
    "    raw_poses = np.array(df['POSES'].apply(parse_poses_from_string).tolist())\n",
    "    \n",
    "    # Normalized Positions\n",
    "    neck_positions = raw_poses[:, 1:2, :]\n",
    "    normalized_poses = raw_poses - neck_positions\n",
    "    \n",
    "    # Velocities\n",
    "    velocities = np.diff(raw_poses, axis=0, prepend=raw_poses[0:1])\n",
    "    \n",
    "    # Orientation Angle\n",
    "    neck_trajectory = raw_poses[:, 1, :]\n",
    "    deltas = np.diff(neck_trajectory, axis=0, prepend=[neck_trajectory[0]])\n",
    "    orientation_angles_deg = np.degrees(np.arctan2(deltas[:, 1], deltas[:, 0]))\n",
    "    \n",
    "    # Combine Features\n",
    "    return np.concatenate([\n",
    "        normalized_poses.reshape(raw_poses.shape[0], -1),\n",
    "        velocities.reshape(raw_poses.shape[0], -1),\n",
    "        orientation_angles_deg.reshape(-1, 1)\n",
    "    ], axis=1)\n",
    "\n",
    "# --- Execute ---\n",
    "set_seed(SEED)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the Kaggle data root directory\n",
    "data_root = '/kaggle/input/skeleton-poses-normalvsshoplifter/csvs_Skeleton_poses_normal_potential_shoplifter/'\n",
    "\n",
    "# Load file paths and create labels\n",
    "df_files = load_and_label_files(data_root)\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_id(file_path: str) -> str:\n",
    "    \"\"\"Extracts a unique group identifier from the file path.\"\"\"\n",
    "    return os.path.basename(file_path).replace('.csv', '')[-23:]\n",
    "\n",
    "def create_sliding_windows(sequences: list, labels: list, window_size: int, step_size: int):\n",
    "    \"\"\"Creates overlapping windows from full sequences.\"\"\"\n",
    "    windowed_sequences, windowed_labels = [], []\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if seq.shape[0] >= window_size:\n",
    "            for start in range(0, seq.shape[0] - window_size + 1, step_size):\n",
    "                windowed_sequences.append(seq[start:start + window_size])\n",
    "                windowed_labels.append(labels[i])\n",
    "    return np.array(windowed_sequences), np.array(windowed_labels)\n",
    "\n",
    "# --- Step 1: Process all files into memory ---\n",
    "print(\"--- Processing all CSV files into feature sequences ---\")\n",
    "all_sequences, all_labels, all_groups, all_paths = [], [], [], []\n",
    "for _, row in tqdm(df_files.iterrows(), total=len(df_files), desc=\"Extracting Features\"):\n",
    "    features = extract_features(row['path'])\n",
    "    if features is not None and len(features) > 0:\n",
    "        all_sequences.append(features)\n",
    "        all_labels.append(row['label'])\n",
    "        all_groups.append(get_group_id(row['path']))\n",
    "        all_paths.append(row['path']) # <-- ADDED: Keep track of paths\n",
    "\n",
    "# --- Step 2: Split groups into Training and Temp (Val + Test) sets ---\n",
    "print(\"\\n--- Splitting data by group to prevent leakage ---\")\n",
    "gss_train_temp = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_group_indices, temp_group_indices = next(gss_train_temp.split(all_sequences, all_labels, all_groups))\n",
    "\n",
    "train_sequences = [all_sequences[i] for i in train_group_indices]\n",
    "train_labels = [all_labels[i] for i in train_group_indices]\n",
    "\n",
    "temp_sequences = [all_sequences[i] for i in temp_group_indices]\n",
    "temp_labels = [all_labels[i] for i in temp_group_indices]\n",
    "temp_groups = np.array(all_groups)[temp_group_indices]\n",
    "temp_paths = [all_paths[i] for i in temp_group_indices] # <-- ADDED: Track paths for temp set\n",
    "\n",
    "# --- Step 3: Create all training, validation, and test datasets ---\n",
    "print(\"\\n--- Creating datasets: augmented for training, and both windowed & full-length for val/test ---\")\n",
    "X_train_windowed, y_train_windowed = create_sliding_windows(\n",
    "    train_sequences, train_labels, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES\n",
    ")\n",
    "\n",
    "gss_val_test = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "val_indices, test_indices = next(gss_val_test.split(temp_sequences, temp_labels, temp_groups))\n",
    "\n",
    "# Create full-length validation and test sets\n",
    "X_val_long = [temp_sequences[i] for i in val_indices]\n",
    "y_val_long = [temp_labels[i] for i in val_indices]\n",
    "X_test_long = [temp_sequences[i] for i in test_indices]\n",
    "y_test_long = [temp_labels[i] for i in test_indices]\n",
    "# Keep track of the final test paths\n",
    "test_paths_long = [temp_paths[i] for i in test_indices] # <-- ADDED: Final test paths\n",
    "\n",
    "# Create the windowed versions for validation and test\n",
    "X_val_windowed, y_val_windowed = create_sliding_windows(X_val_long, y_val_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "X_test_windowed, y_test_windowed = create_sliding_windows(X_test_long, y_test_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "\n",
    "# --- Step 4: Create PyTorch DataLoaders ---\n",
    "X_train_tensor = torch.from_numpy(X_train_windowed).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_windowed).long()\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=g)\n",
    "\n",
    "# --- Final Summary ---\n",
    "print(\"\\n--- Data Preparation Complete ---\")\n",
    "print(f\"Total original videos processed: {len(all_sequences)}\")\n",
    "print(f\"Training on {len(X_train_tensor)} augmented windows (from {len(train_sequences)} videos).\")\n",
    "print(f\"Validating on {len(X_val_long)} full-length videos.\")\n",
    "print(f\"Testing on {len(X_test_long)} full-length videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Architecture ---\n",
    "class RealTimeClassifier(nn.Module):\n",
    "    \"\"\"LSTM-based classifier with an Attention mechanism.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_rate=0.5):\n",
    "        super(RealTimeClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the model.\"\"\"\n",
    "        out, _ = self.lstm(x)\n",
    "        attention_scores = self.attention(out)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        context_vector = torch.sum(attention_weights * out, dim=1)\n",
    "        context_vector_dropped = self.dropout(context_vector)\n",
    "        return self.fc(context_vector_dropped)\n",
    "\n",
    "# --- Loss Function for Imbalanced Data ---\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss function to address class imbalance.\"\"\"\n",
    "    def __init__(self, alpha: torch.Tensor, gamma: float = 2.0, reduction: str = 'mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculates the focal loss.\"\"\"\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.alpha[targets] * (1 - pt)**self.gamma * ce_loss)\n",
    "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum()\n",
    "\n",
    "# --- Evaluation & Reporting Helper Functions ---\n",
    "def evaluate_and_report_on_test_set(\n",
    "    model: nn.Module,\n",
    "    test_sequences: list[np.ndarray],\n",
    "    test_labels: list[int],\n",
    "    device: torch.device\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs the final evaluation on the test set using three methods:\n",
    "    1. Per-window classification.\n",
    "    2. Per-video classification (simple aggregation).\n",
    "    3. Per-video classification with an optimized suspicion threshold.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_window_preds, all_window_labels = [], []\n",
    "    video_suspicion_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, long_seq_np in enumerate(tqdm(test_sequences, desc=\"Evaluating Test Set\")):\n",
    "            y_true_video = test_labels[i]\n",
    "            seq_windows_tensors = []\n",
    "            \n",
    "            # Create windows for the current video\n",
    "            if long_seq_np.shape[0] >= WINDOW_SIZE_FRAMES:\n",
    "                for start in range(0, long_seq_np.shape[0] - WINDOW_SIZE_FRAMES + 1, STEP_SIZE_FRAMES):\n",
    "                    window = long_seq_np[start:start + WINDOW_SIZE_FRAMES]\n",
    "                    seq_windows_tensors.append(torch.from_numpy(window))\n",
    "            \n",
    "            if not seq_windows_tensors:\n",
    "                video_suspicion_scores.append(0.0)\n",
    "                continue\n",
    "\n",
    "            windows_batch = torch.stack(seq_windows_tensors).float().to(device)\n",
    "            outputs = model(windows_batch)\n",
    "            \n",
    "            # For per-window report\n",
    "            _, predicted_windows = torch.max(outputs, 1)\n",
    "            all_window_preds.extend(predicted_windows.cpu().numpy())\n",
    "            all_window_labels.extend([y_true_video] * len(predicted_windows))\n",
    "            \n",
    "            # For suspicion score thresholding\n",
    "            probabilities = torch.softmax(outputs, dim=1)[:, 1] # Probability of 'Shoplifter' class\n",
    "            avg_suspicion_score = probabilities.mean().item()\n",
    "            video_suspicion_scores.append(avg_suspicion_score)\n",
    "\n",
    "    # --- Method 1: Per-Window Report ---\n",
    "    plot_report_and_matrix(all_window_labels, all_window_preds, \"Test Set Evaluation (Per-Window)\")\n",
    "    \n",
    "    # --- Method 2: Simple Per-Video Report (Flag if any window is positive) ---\n",
    "    # This logic is inside `evaluate_realistically`, so we call it here for consistency\n",
    "    simple_accuracy = evaluate_realistically(model, test_sequences, test_labels, device, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES)\n",
    "    print(f\"\\n--- Test Set Evaluation (Simple Per-Video) ---\")\n",
    "    print(f\"Accuracy (if any window is 1, predict 1): {simple_accuracy:.2f}%\")\n",
    "\n",
    "    # --- Method 3: Smart Thresholding Report ---\n",
    "    y_true_video_labels = test_labels\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_video_labels, video_suspicion_scores)\n",
    "    # Use np.nan_to_num to avoid division by zero warnings\n",
    "    f1_scores = np.nan_to_num(2 * (precisions * recalls) / (precisions + recalls))\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    \n",
    "    y_pred_thresholded = [1 if score >= best_threshold else 0 for score in video_suspicion_scores]\n",
    "    plot_report_and_matrix(y_true_video_labels, y_pred_thresholded, f\"Test Set Evaluation (Optimal Threshold: {best_threshold:.2f})\")\n",
    "\n",
    "def plot_report_and_matrix(y_true, y_pred, title):\n",
    "    \"\"\"Generates and prints a classification report and plots a confusion matrix.\"\"\"\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Normal', 'Potential Shoplifter'], zero_division=0))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Normal', 'Potential Shoplifter'], yticklabels=['Normal', 'Potential Shoplifter'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_realistically(model, long_sequences, long_labels, device, window_size, step_size):\n",
    "    \"\"\"Evaluates accuracy on full videos using simple aggregation.\"\"\"\n",
    "    model.eval()\n",
    "    y_pred_final = []\n",
    "    with torch.no_grad():\n",
    "        for long_seq_np in long_sequences:\n",
    "            seq_windows_tensors = []\n",
    "            if long_seq_np.shape[0] >= window_size:\n",
    "                for start in range(0, long_seq_np.shape[0] - window_size + 1, step_size):\n",
    "                    seq_windows_tensors.append(torch.from_numpy(long_seq_np[start:start + window_size]))\n",
    "            \n",
    "            if not seq_windows_tensors:\n",
    "                final_video_prediction = 0\n",
    "            else:\n",
    "                outputs = model(torch.stack(seq_windows_tensors).float().to(device))\n",
    "                final_video_prediction = 1 if 1 in torch.max(outputs, 1)[1] else 0\n",
    "            y_pred_final.append(final_video_prediction)\n",
    "    return accuracy_score(long_labels, y_pred_final) * 100\n",
    "\n",
    "print(\"Model architecture, loss functions, and evaluation helpers are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_online_training_trial(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_windowed_loader: DataLoader,\n",
    "    val_long_sequences: list[np.ndarray],\n",
    "    val_long_labels: list[int],\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    num_epochs: int,\n",
    "    model_save_path_window: str,\n",
    "    model_save_path_realistic: str,\n",
    "    device: torch.device\n",
    "):\n",
    "    \"\"\"\n",
    "    Executes a full training trial for the online approach.\n",
    "    It validates using two methods and saves the best model for each.\n",
    "    \"\"\"\n",
    "    best_val_acc_window = 0.0\n",
    "    best_val_acc_realistic = 0.0\n",
    "\n",
    "    # History for plotting\n",
    "    history = {'train_loss': [], 'val_acc_window': [], 'val_acc_realistic': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} | Training\")\n",
    "        for sequences, labels in train_pbar:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        # Method 1: Per-window accuracy\n",
    "        correct_window, total_window = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_windowed_loader:\n",
    "                sequences, labels = sequences.to(device), labels.to(device)\n",
    "                outputs = model(sequences)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_window += labels.size(0)\n",
    "                correct_window += (predicted == labels).sum().item()\n",
    "        epoch_acc_val_window = 100 * correct_window / total_window\n",
    "        history['val_acc_window'].append(epoch_acc_val_window)\n",
    "\n",
    "        # Method 2: Realistic per-video accuracy\n",
    "        epoch_acc_val_realistic = evaluate_realistically(\n",
    "            model, val_long_sequences, val_long_labels, device, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES\n",
    "        )\n",
    "        history['val_acc_realistic'].append(epoch_acc_val_realistic)\n",
    "        \n",
    "        # --- Epoch Summary ---\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Window Val Acc: {epoch_acc_val_window:.2f}% | \"\n",
    "              f\"Realistic Val Acc: {epoch_acc_val_realistic:.2f}%\")\n",
    "        \n",
    "        # Save best model based on PER-WINDOW accuracy\n",
    "        if epoch_acc_val_window > best_val_acc_window:\n",
    "            best_val_acc_window = epoch_acc_val_window\n",
    "            torch.save(model.state_dict(), model_save_path_window)\n",
    "            print(f\"---> New best WINDOW model saved (Val Acc: {best_val_acc_window:.2f}%)\")\n",
    "            \n",
    "        # Save best model based on REALISTIC (per-video) accuracy\n",
    "        if epoch_acc_val_realistic > best_val_acc_realistic:\n",
    "            best_val_acc_realistic = epoch_acc_val_realistic\n",
    "            torch.save(model.state_dict(), model_save_path_realistic)\n",
    "            print(f\"---> New best REALISTIC model saved (Val Acc: {best_val_acc_realistic:.2f}%)\")\n",
    "            \n",
    "    print(\"\\n--- Finished Training Trial ---\")\n",
    "    return history\n",
    "\n",
    "# --- Main Script for this Cell ---\n",
    "print(\"Trial 1: Training with Standard CrossEntropy Loss\")\n",
    "set_seed(SEED)\n",
    "\n",
    "# Instantiate a fresh model\n",
    "ce_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "\n",
    "# Define criterion and optimizer\n",
    "ce_criterion = nn.CrossEntropyLoss()\n",
    "ce_optimizer = optim.Adam(ce_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Define paths for the two best models we'll save\n",
    "ce_model_path_window = 'best_ce_model_window.pth'\n",
    "ce_model_path_realistic = 'best_ce_model_realistic.pth'\n",
    "\n",
    "# Run the training\n",
    "ce_history = run_online_training_trial(\n",
    "    model=ce_model,\n",
    "    train_loader=train_loader,\n",
    "    val_windowed_loader=val_windowed_loader,\n",
    "    val_long_sequences=X_val_long,\n",
    "    val_long_labels=y_val_long,\n",
    "    criterion=ce_criterion,\n",
    "    optimizer=ce_optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model_save_path_window=ce_model_path_window,\n",
    "    model_save_path_realistic=ce_model_path_realistic,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: dict, trial_name: str):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Training Loss', color='tab:red')\n",
    "    ax1.plot(history['train_loss'], 'r-', label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "    ax2.plot(history['val_acc_window'], 'b--', label='Window Val Acc')\n",
    "    ax2.plot(history['val_acc_realistic'], 'g-.', label='Realistic Val Acc')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f'{trial_name} - Training History', y=1.03)\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Script for this Cell ---\n",
    "\n",
    "# 1. Plot the training history from the Cross-Entropy trial\n",
    "print(\"Plotting Training History for Trial 1 (CrossEntropy)\")\n",
    "plot_history(ce_history, \"CrossEntropy Loss\")\n",
    "\n",
    "# 2. Load the best-performing model based on REALISTIC validation accuracy\n",
    "print(\"\\nLoading best model for final evaluation on the Test Set\")\n",
    "set_seed(SEED) # Reset seed for model instantiation consistency\n",
    "final_ce_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "# Load the state dictionary saved from the validation loop\n",
    "final_ce_model.load_state_dict(torch.load(ce_model_path_realistic))\n",
    "print(f\"Model loaded successfully from: {ce_model_path_realistic}\")\n",
    "\n",
    "# 3. Perform comprehensive evaluation on the TEST set\n",
    "evaluate_and_report_on_test_set(\n",
    "    model=final_ce_model,\n",
    "    test_sequences=X_test_long,\n",
    "    test_labels=y_test_long,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Script for this Cell ---\n",
    "print(\"Loading best model optimized for perwindow performance\")\n",
    "set_seed(SEED)\n",
    "\n",
    "# Instantiate a fresh model\n",
    "window_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "\n",
    "# Load the state dictionary saved from the validation loop\n",
    "window_model.load_state_dict(torch.load(ce_model_path_window)) \n",
    "window_model.eval()\n",
    "\n",
    "# 2. Get all per-window predictions to identify videos with failures\n",
    "all_window_preds = []\n",
    "_, y_test_windowed_labels, test_window_source_indices = create_sliding_windows_with_indices(\n",
    "    X_test_long, y_test_long, WINDOW_SIZE_FRAMES, STEP_SIZE_FRAMES\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, _ in tqdm(test_windowed_loader, desc=\"Getting Per-Window Predictions\"):\n",
    "        outputs = window_model(sequences.to(device))\n",
    "        all_window_preds.extend(torch.max(outputs.data, 1)[1].cpu().numpy())\n",
    "\n",
    "# 3. Identify the source video indices that contain failures\n",
    "fn_video_indices = set() # False Negatives (True Shoplifter, Predicted Normal)\n",
    "fp_video_indices = set() # False Positives (True Normal, Predicted Shoplifter)\n",
    "\n",
    "for i, (pred, true) in enumerate(zip(all_window_preds, y_test_windowed_labels)):\n",
    "    if pred != true:\n",
    "        source_idx = test_window_source_indices[i]\n",
    "        if true == 1:\n",
    "            fn_video_indices.add(source_idx)\n",
    "        else:\n",
    "            fp_video_indices.add(source_idx)\n",
    "\n",
    "print(f\"\\nIdentified {len(fn_video_indices)} videos with Shoplifter misclassifications.\")\n",
    "print(f\"Identified {len(fp_video_indices)} videos with Normal Pedestrian misclassifications.\")\n",
    "\n",
    "# 4. Plot trajectories, mimicking the paper's layout\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Fig 9. Samples from failure cases', fontsize=18, y=0.95)\n",
    "\n",
    "# Left Column: UroKyoro Failure Cases (False Negatives)\n",
    "fn_indices_list = list(fn_video_indices)\n",
    "axes[0, 0].set_title('Shoplifter Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 0]):\n",
    "    if i < len(fn_indices_list):\n",
    "        idx = fn_indices_list[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False) # Hide unused subplots\n",
    "\n",
    "# Right Column: Normal Pedestrian Failure Cases (False Positives)\n",
    "fp_indices_list = list(fp_video_indices)\n",
    "axes[0, 1].set_title('Normal Pedestrian Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 1]):\n",
    "    if i < len(fp_indices_list):\n",
    "        idx = fp_indices_list[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Script for this Cell ---\n",
    "print(\" Trial 2: Training with Focal Loss \")\n",
    "set_seed(SEED)\n",
    "\n",
    "# Instantiate a fresh model for this new trial\n",
    "focal_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "\n",
    "# --- Set up Focal Loss ---\n",
    "# Calculate alpha weights to counter class imbalance.\n",
    "# The weights are the inverse of the class frequencies.\n",
    "# Original counts: 88 Normal (class 0), 64 Shoplifter (class 1)\n",
    "total_videos = 88 + 64\n",
    "# Weight for class 0 = (fraction of class 1)\n",
    "alpha_class_0 = 64 / total_videos\n",
    "# Weight for class 1 = (fraction of class 0)\n",
    "alpha_class_1 = 88 / total_videos\n",
    "alpha_tensor = torch.tensor([alpha_class_0, alpha_class_1]).to(device)\n",
    "\n",
    "print(f\"Calculated alpha weights for Focal Loss: {alpha_tensor.cpu().numpy()}\")\n",
    "\n",
    "# Instantiate the Focal Loss function and a new optimizer\n",
    "focal_criterion = FocalLoss(alpha=alpha_tensor, gamma=2.0)\n",
    "focal_optimizer = optim.Adam(focal_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Define the paths for the saved models from this trial\n",
    "focal_model_path_window = 'best_focal_model_window.pth'\n",
    "focal_model_path_realistic = 'best_focal_model_realistic.pth'\n",
    "\n",
    "# Run the training trial using the same helper function as before\n",
    "focal_history = run_online_training_trial(\n",
    "    model=focal_model,\n",
    "    train_loader=train_loader,\n",
    "    val_windowed_loader=val_windowed_loader,\n",
    "    val_long_sequences=X_val_long,\n",
    "    val_long_labels=y_val_long,\n",
    "    criterion=focal_criterion,\n",
    "    optimizer=focal_optimizer,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    model_save_path_window=focal_model_path_window,\n",
    "    model_save_path_realistic=focal_model_path_realistic,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Script for this Cell ---\n",
    "\n",
    "# 1. Plot the training history from the Focal Loss trial\n",
    "print(\" Plotting Training History for Trial 2 (Focal Loss) \")\n",
    "plot_history(focal_history, \"Focal Loss\")\n",
    "\n",
    "# 2. Load the best-performing model based on REALISTIC validation accuracy\n",
    "print(\"\\n--- Loading best Focal Loss model for final evaluation on the Test Set ---\")\n",
    "set_seed(SEED) # Reset seed for model instantiation consistency\n",
    "final_focal_model = RealTimeClassifier(INPUT_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)\n",
    "final_focal_model.load_state_dict(torch.load(focal_model_path_realistic))\n",
    "print(f\"Model loaded successfully from: {focal_model_path_realistic}\")\n",
    "\n",
    "# 3. Perform comprehensive evaluation on the TEST set\n",
    "evaluate_and_report_on_test_set(\n",
    "    model=final_focal_model,\n",
    "    test_sequences=X_test_long,\n",
    "    test_labels=y_test_long,\n",
    "    device=device\n",
    ")\n",
    "print(\"\\nVisualizing Failure Cases for Trial 2 (Focal Loss)\")\n",
    "focal_test_predictions = get_model_predictions_for_test_set(final_focal_model, X_test_long, y_test_long, device)\n",
    "focal_failure_indices = [i for i, (pred, true) in enumerate(zip(focal_test_predictions, y_test_long)) if pred != true]\n",
    "fn_failures_focal = [i for i in focal_failure_indices if y_test_long[i] == 1]\n",
    "fp_failures_focal = [i for i in focal_failure_indices if y_test_long[i] == 0]\n",
    "print(f\"Identified {len(focal_failure_indices)} total failure cases for the Focal Loss model.\")\n",
    "print(f\" {len(fn_failures_focal)} False Negatives (Missed Shoplifters)\")\n",
    "print(f\" {len(fp_failures_focal)} False Positives (Incorrectly Flagged Normals)\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Fig 9. Samples from failure cases (Focal Loss Model)', fontsize=18, y=0.95)\n",
    "fn_indices_list_focal = list(fn_failures_focal)\n",
    "axes[0, 0].set_title('UroKyoro Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 0]):\n",
    "    if i < len(fn_indices_list_focal):\n",
    "        idx = fn_indices_list_focal[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "fp_indices_list_focal = list(fp_failures_focal)\n",
    "axes[0, 1].set_title('Normal Pedestrian Failure Cases', fontsize=14)\n",
    "for i, ax in enumerate(axes[:, 1]):\n",
    "    if i < len(fp_indices_list_focal):\n",
    "        idx = fp_indices_list_focal[i]\n",
    "        plot_trajectory(test_paths_long[idx], ax)\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.93])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch_geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "\n",
    "print(\"PyTorch Geometric and its dependencies have been installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import PyTorch Geometric libraries\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"--- Imports for Graph Convolutional Network (GCN) Approach ---\")\n",
    "\n",
    "# --- Configuration & Seeding ---\n",
    "SEED = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model and training constants\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "# We will define other model-specific constants later\n",
    "\n",
    "def set_seed(seed_value: int):\n",
    "    \"\"\"Sets the seed for reproducibility for all relevant libraries.\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Global seed set to {seed_value}\")\n",
    "\n",
    "# --- Execute ---\n",
    "set_seed(SEED)\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"All necessary libraries and configurations are set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FRAMES = 300\n",
    "\n",
    "edge_index = torch.tensor([\n",
    "    # Torso\n",
    "    [1, 2], [1, 5], [2, 8], [5, 11], [8, 11], [1, 0],\n",
    "    # Left Arm\n",
    "    [2, 3], [3, 4],\n",
    "    # Right Arm\n",
    "    [5, 6], [6, 7],\n",
    "    # Left Leg\n",
    "    [8, 9], [9, 10],\n",
    "    # Right Leg\n",
    "    [11, 12], [12, 13]\n",
    "], dtype=torch.long).t().contiguous()\n",
    "\n",
    "def load_and_label_files(data_root: str) -> pd.DataFrame:\n",
    "    \"\"\"Finds all CSVs, labels them based on the folder, and returns a DataFrame.\"\"\"\n",
    "    all_csv_files = glob(os.path.join(data_root, '**', '*.csv'), recursive=True)\n",
    "    labeled_data = [{'path': file_path, 'label': 1 if 'Potential_shoplifter' in file_path else 0} for file_path in all_csv_files]\n",
    "    df_files = pd.DataFrame(labeled_data)\n",
    "    print(f\"Found {len(df_files)} total CSV files.\")\n",
    "    return df_files\n",
    "\n",
    "def parse_poses_from_string(poses_str: str) -> np.ndarray:\n",
    "    \"\"\"Helper to parse the 'POSES' string into a numpy array.\"\"\"\n",
    "    try:\n",
    "        return np.array(json.loads(poses_str)).reshape(18, 2)\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return np.zeros((18, 2))\n",
    "\n",
    "\n",
    "class SkeletonDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Geometric Dataset for loading skeleton action recognition data.\n",
    "    Each video is represented as a single graph.\n",
    "    - Nodes: The 18 skeleton joints.\n",
    "    - Node Features: The flattened (x, y) coordinates of each joint across all frames.\n",
    "    - Edges: The predefined bone connections.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, max_frames: int):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.max_frames = max_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        csv_path = row['path']\n",
    "        label = row['label']\n",
    "\n",
    "        # Load and parse pose data from the CSV\n",
    "        df_poses = pd.read_csv(csv_path)\n",
    "        raw_poses = np.array(df_poses['POSES'].apply(parse_poses_from_string).tolist()) # Shape: (n_frames, 18, 2)\n",
    "\n",
    "        # --- Temporal Padding/Truncating ---\n",
    "        n_frames = raw_poses.shape[0]\n",
    "        if n_frames < self.max_frames:\n",
    "            # Pad with zeros if the sequence is too short\n",
    "            padding = np.zeros((self.max_frames - n_frames, 18, 2))\n",
    "            processed_poses = np.concatenate([raw_poses, padding], axis=0)\n",
    "        else:\n",
    "            # Truncate if the sequence is too long\n",
    "            processed_poses = raw_poses[:self.max_frames, :, :]\n",
    "\n",
    "        # --- Feature Engineering ---\n",
    "        # The feature for each node (joint) is its entire trajectory.\n",
    "        # Reshape to (num_nodes, features_per_node) where features are (max_frames * 2)\n",
    "        node_features = torch.tensor(processed_poses.transpose(1, 0, 2).reshape(18, -1), dtype=torch.float)\n",
    "\n",
    "        # Create the graph data object\n",
    "        data = Data(\n",
    "            x=node_features,         # Node features: Shape [18, max_frames * 2]\n",
    "            edge_index=edge_index,   # Graph connectivity\n",
    "            y=torch.tensor([label], dtype=torch.long) # Label\n",
    "        )\n",
    "        return data\n",
    "\n",
    "data_root = '/kaggle/input/skeleton-poses-normalvsshoplifter/csvs_Skeleton_poses_normal_potential_shoplifter/'\n",
    "df_files = load_and_label_files(data_root)\n",
    "full_dataset = SkeletonDataset(df=df_files, max_frames=MAX_FRAMES)\n",
    "\n",
    "print(f\"\\nSuccessfully created a dataset with {len(full_dataset)} graphs.\")\n",
    "print(\"\\nExample of a single graph data object from the dataset:\")\n",
    "print(full_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "def get_group_id(file_path: str) -> str:\n",
    "    return os.path.basename(file_path).replace('.csv', '')[-23:]\n",
    "groups = [get_group_id(path) for path in df_files['path']]\n",
    "labels = df_files['label'].values\n",
    "indices = np.arange(len(full_dataset))\n",
    "gss_train_temp = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_indices, temp_indices = next(gss_train_temp.split(indices, labels, groups))\n",
    "gss_val_test = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=SEED)\n",
    "val_indices, test_indices = next(gss_val_test.split(\n",
    "    indices[temp_indices],\n",
    "    labels[temp_indices],\n",
    "    np.array(groups)[temp_indices]\n",
    "))\n",
    "final_val_indices = temp_indices[val_indices]\n",
    "final_test_indices = temp_indices[test_indices]\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, final_val_indices)\n",
    "test_dataset = Subset(full_dataset, final_test_indices)\n",
    "train_loader = PyGDataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = PyGDataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = PyGDataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"--- Data Splitting and DataLoader Creation Complete ---\")\n",
    "print(f\"Total graphs: {len(full_dataset)}\")\n",
    "print(f\"Training graphs: {len(train_dataset)}\")\n",
    "print(f\"Validation graphs: {len(val_dataset)}\")\n",
    "print(f\"Testing graphs: {len(test_dataset)}\")\n",
    "print(f\"\\nCreated PyG DataLoaders with batch size {BATCH_SIZE}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "class SkeletonGCN(nn.Module):\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(SEED)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x_pooled = global_mean_pool(x, batch)\n",
    "        out = self.classifier(x_pooled)\n",
    "        return out\n",
    "model = SkeletonGCN(\n",
    "    in_channels=MAX_FRAMES * 2,\n",
    "    hidden_channels=128,\n",
    "    out_channels=2\n",
    ").to(device)\n",
    "print(\"--- GCN Model Architecture ---\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_gcn(\n",
    "    model: nn.Module,\n",
    "    loader: PyGDataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in tqdm(loader, desc=\"Training\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "def evaluate_gcn(\n",
    "    model: nn.Module,\n",
    "    loader: PyGDataLoader\n",
    ") -> tuple[float, list, list]:\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(loader, desc=\"Evaluating\"):\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    return accuracy, all_preds, all_labels\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(\"Training and evaluation functions are defined.\")\n",
    "print(\"Criterion: CrossEntropyLoss\")\n",
    "print(\"Optimizer: Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = 0.0\n",
    "model_save_path = 'best_gcn_model.pth'\n",
    "history = {'train_loss': [], 'val_acc': []}\n",
    "print(\"--- Starting GCN Model Training ---\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_one_epoch_gcn(model, train_loader, optimizer, criterion)\n",
    "    val_accuracy, _, _ = evaluate_gcn(model, val_loader)\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_accuracy)\n",
    "    print(f\"Epoch: {epoch:02d} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Val Acc: {val_accuracy:.2f}% | \"\n",
    "          f\"Duration: {epoch_duration:.2f}s\")\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"==> New best model saved with Val Acc: {best_val_accuracy:.2f}%\")\n",
    "print(\"\\n--- Finished Training ---\")\n",
    "print(f\"The best model was saved to '{model_save_path}' with a validation accuracy of {best_val_accuracy:.2f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gcn_history(history: dict):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Training Loss', color='tab:red')\n",
    "    ax1.plot(history['train_loss'], 'r-', label='Training Loss')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Validation Accuracy (%)', color='tab:blue')\n",
    "    ax2.plot(history['val_acc'], 'b--', label='Validation Acc')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax2.set_ylim(0, 105)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle('GCN Model - Training History', y=1.03)\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(0.9, 0.9))\n",
    "    plt.show()\n",
    "print(\"--- Plotting GCN Training History ---\")\n",
    "plot_gcn_history(history)\n",
    "print(\"\\n--- Loading best model for final evaluation on the Test Set ---\")\n",
    "final_model = SkeletonGCN(\n",
    "    in_channels=MAX_FRAMES * 2,\n",
    "    hidden_channels=128,\n",
    "    out_channels=2\n",
    ").to(device)\n",
    "final_model.load_state_dict(torch.load(model_save_path))\n",
    "print(f\"Model loaded successfully from: {model_save_path}\")\n",
    "test_accuracy, test_preds, test_labels = evaluate_gcn(final_model, test_loader)\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.2f}%\")\n",
    "plot_report_and_matrix(\n",
    "    y_true=test_labels,\n",
    "    y_pred=test_preds,\n",
    "    title=\"GCN Final Test Set Performance\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8036220,
     "sourceId": 12714869,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
